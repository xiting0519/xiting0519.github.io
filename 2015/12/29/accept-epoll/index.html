<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>accept与epoll惊群 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="今天打开 OneNote,发现里面躺着一篇很久以前写的笔记，现在将它贴出来。
1. 什么叫惊群现象首先，我们看看维基百科对惊群的定义:

The thundering herd problem occurs when a large number of processes waiting for an event are awoken when that event occurs, but onl">
<meta property="og:type" content="article">
<meta property="og:title" content="accept与epoll惊群">
<meta property="og:url" content="http://yoursite.com/2015/12/29/accept-epoll/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="今天打开 OneNote,发现里面躺着一篇很久以前写的笔记，现在将它贴出来。
1. 什么叫惊群现象首先，我们看看维基百科对惊群的定义:

The thundering herd problem occurs when a large number of processes waiting for an event are awoken when that event occurs, but onl">
<meta property="og:updated_time" content="2015-12-29T15:41:50.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="accept与epoll惊群">
<meta name="twitter:description" content="今天打开 OneNote,发现里面躺着一篇很久以前写的笔记，现在将它贴出来。
1. 什么叫惊群现象首先，我们看看维基百科对惊群的定义:

The thundering herd problem occurs when a large number of processes waiting for an event are awoken when that event occurs, but onl">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-accept-epoll" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/12/29/accept-epoll/" class="article-date">
  <time datetime="2015-12-29T15:41:00.000Z" itemprop="datePublished">2015-12-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      accept与epoll惊群
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>今天打开 OneNote,发现里面躺着一篇很久以前写的笔记，现在将它贴出来。</p>
<h2 id="1-__u4EC0_u4E48_u53EB_u60CA_u7FA4_u73B0_u8C61"><a href="#1-__u4EC0_u4E48_u53EB_u60CA_u7FA4_u73B0_u8C61" class="headerlink" title="1. 什么叫惊群现象"></a>1. 什么叫惊群现象</h2><p>首先，我们看看<a href="http://en.wikipedia.org/wiki/Thundering_herd_problem" target="_blank" rel="external">维基百科对惊群的定义</a>:</p>
<blockquote>
<p>The thundering herd problem occurs when a large number of processes waiting for an event are awoken when that event occurs, but only one process is able to proceed at a time. After the processes wake up, they all demand the resource and a decision must be made as to which process can continue. After the decision is made, the remaining processes are put back to sleep, only to all wake up again to request access to the resource.</p>
<p>This occurs repeatedly, until there are no more processes to be woken up. Because all the processes use system resources upon waking, it is more efficient if only one process was woken up at a time.</p>
<p>This may render the computer unusable, but it can also be used as a technique if there is no other way to decide which process should continue (for example when programming with semaphores).</p>
</blockquote>
<p>简而言之，惊群现象（thundering herd）就是当多个进程和线程在同时阻塞等待同一个事件时，如果这个事件发生，会唤醒所有的进程，但最终只可能有一个进程/线程对该事件进行处理，其他进程/线程会在失败后重新休眠，这种性能浪费就是惊群。</p>
<a id="more"></a>
<h2 id="2-_accept__u60CA_u7FA4"><a href="#2-_accept__u60CA_u7FA4" class="headerlink" title="2. accept 惊群"></a>2. accept 惊群</h2><p>考虑如下场景：<br>主进程创建socket, bind, listen之后，fork出多个子进程，每个子进程都开始循环处理（accept)这个socket。每个进程都阻塞在accpet上，当一个新的连接到来时，所有的进程都会被唤醒，但其中只有一个进程会accept成功，其余皆失败，重新休眠。这就是accept惊群。</p>
<p>那么这个问题真的存在吗？</p>
<p>事实上，历史上，Linux 的 accpet 确实存在惊群问题，但现在的内核都解决该问题了。即，当多个进程/线程都阻塞在对同一个 socket 的 accept 调用上时，当有一个新的连接到来，内核只会唤醒一个进程，其他进程保持休眠，压根就不会被唤醒。</p>
<p>测试代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#include &#60;sys/types.h&#62;&#10;#include &#60;sys/socket.h&#62;&#10;#include &#60;netinet/in.h&#62;&#10;#include &#60;sys/wait.h&#62;&#10;#include &#60;stdio.h&#62;&#10;#include &#60;string.h&#62;&#10;#define PROCESS_NUM 10&#10;int main()&#10;&#123;&#10;    int fd = socket(PF_INET, SOCK_STREAM, 0);&#10;    int connfd;&#10;    int pid;&#10;    char sendbuff[1024];&#10;    struct sockaddr_in serveraddr;&#10;    serveraddr.sin_family = AF_INET;&#10;    serveraddr.sin_addr.s_addr = htonl(INADDR_ANY);&#10;    serveraddr.sin_port = htons(1234);&#10;    bind(fd, (struct sockaddr*)&#38;serveraddr, sizeof(serveraddr));&#10;    listen(fd, 1024);&#10;    int i;&#10;    for(i = 0; i &#60; PROCESS_NUM; i++)&#10;    &#123;&#10;        int pid = fork();&#10;        if(pid == 0)&#10;        &#123;&#10;            while(1)&#10;            &#123;&#10;                connfd = accept(fd, (struct sockaddr*)NULL, NULL);&#10;                snprintf(sendbuff, sizeof(sendbuff), &#34;accept PID is %d\n&#34;, getpid());&#10;                &#10;                send(connfd, sendbuff, strlen(sendbuff) + 1, 0);&#10;                printf(&#34;process %d accept success!\n&#34;, getpid());&#10;                close(connfd);&#10;            &#125;&#10;        &#125;&#10;    &#125;&#10;    int status;&#10;    wait(&#38;status);&#10;    return 0;&#10;&#125;&#10;```&#9;&#10;&#9;&#10;&#24403;&#25105;&#20204;&#23545;&#35813;&#26381;&#21153;&#22120;&#21457;&#36215;&#36830;&#25509;&#35831;&#27714;&#65288;&#29992; telnet/curl &#31561;&#27169;&#25311;&#65289;&#26102;&#65292;&#20250;&#30475;&#21040;&#21482;&#26377;&#19968;&#20010;&#36827;&#31243;&#34987;&#21796;&#37266;&#12290;&#10;&#9;&#10;&#20851;&#20110; accept &#24778;&#32676;&#30340;&#19968;&#20123;&#24086;&#23376;&#25110;&#25991;&#31456;&#65306;&#10;&#10;* [&#24778;&#32676;&#38382;&#39064;&#22312; linux &#19978;&#21487;&#33021;&#26159;&#33707;&#39035;&#26377;&#30340;&#38382;&#39064;][2]&#10;* [Does the Thundering Herd Problem exist on Linux anymore?][3]&#10;* [&#21382;&#21490;&#19978;&#35299;&#20915; linux accept &#24778;&#32676;&#30340;&#34917;&#19969;&#35752;&#35770;][4]&#10;&#10;## 3. epoll&#24778;&#32676;&#10;&#10;&#22914;&#19978;&#25152;&#36848;&#65292;accept &#24050;&#32463;&#19981;&#23384;&#22312;&#24778;&#32676;&#38382;&#39064;&#65292;&#20294; epoll &#19978;&#36824;&#26159;&#23384;&#22312;&#24778;&#32676;&#38382;&#39064;&#12290;&#21363;&#65292;&#22914;&#26524;&#22810;&#20010;&#36827;&#31243;/&#32447;&#31243;&#38459;&#22622;&#22312;&#30417;&#21548;&#21516;&#19968;&#20010; listening socket fd &#30340; epoll_wait &#19978;&#65292;&#24403;&#26377;&#19968;&#20010;&#26032;&#30340;&#36830;&#25509;&#21040;&#26469;&#26102;&#65292;&#25152;&#26377;&#30340;&#36827;&#31243;&#37117;&#20250;&#34987;&#21796;&#37266;&#12290;&#10;&#9;&#10;&#32771;&#34385;&#22914;&#19979;&#22330;&#26223;&#65306;&#10;&#9;&#10;&#20027;&#36827;&#31243;&#21019;&#24314; socket, bind&#65292; listen &#21518;&#65292;&#23558;&#35813; socket &#21152;&#20837;&#21040; epoll &#20013;&#65292;&#28982;&#21518; fork &#20986;&#22810;&#20010;&#23376;&#36827;&#31243;&#65292;&#27599;&#20010;&#36827;&#31243;&#37117;&#38459;&#22622;&#22312; epoll_wait &#19978;&#65292;&#22914;&#26524;&#26377;&#20107;&#20214;&#21040;&#26469;&#65292;&#21017;&#21028;&#26029;&#35813;&#20107;&#20214;&#26159;&#21542;&#26159;&#35813; socket &#19978;&#30340;&#20107;&#20214;&#65292;&#22914;&#26524;&#26159;&#65292;&#35828;&#26126;&#26377;&#26032;&#30340;&#36830;&#25509;&#21040;&#26469;&#20102;&#65292;&#21017;&#36827;&#34892; accept &#25805;&#20316;&#12290;&#20026;&#20102;&#31616;&#21270;&#22788;&#29702;&#65292;&#24573;&#30053;&#21518;&#32493;&#30340;&#35835;&#20889;&#20197;&#21450;&#23545; accept &#36820;&#22238;&#30340;&#26032;&#30340;&#22871;&#25509;&#23383;&#30340;&#22788;&#29702;&#65292;&#30452;&#25509;&#26029;&#24320;&#36830;&#25509;&#12290;&#10;&#9;&#10;&#37027;&#20040;&#65292;&#24403;&#26032;&#30340;&#36830;&#25509;&#21040;&#26469;&#26102;&#65292;&#26159;&#21542;&#27599;&#20010;&#38459;&#22622;&#22312; epoll_wait &#19978;&#30340;&#36827;&#31243;&#37117;&#20250;&#34987;&#21796;&#37266;&#21602;&#65311;&#10;&#9;&#10;&#24456;&#22810;&#21338;&#23458;&#20013;&#25552;&#21040;&#65292;&#27979;&#35797;&#34920;&#26126;&#34429;&#28982; epoll_wait &#19981;&#20250;&#20687; accept &#37027;&#26679;&#21482;&#21796;&#37266;&#19968;&#20010;&#36827;&#31243;/&#32447;&#31243;&#65292;&#20294;&#20063;&#19981;&#20250;&#25226;&#25152;&#26377;&#30340;&#36827;&#31243;/&#32447;&#31243;&#37117;&#21796;&#37266;&#12290;&#20363;&#22914;&#36825;&#31687;&#25991;&#31456;&#65306;[&#20851;&#20110;&#22810;&#36827;&#31243; epoll &#19982; &#8220;&#24778;&#32676;&#8221;&#38382;&#39064;][5]&#12290;&#10;&#10;&#20026;&#20102;&#39564;&#35777;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#33258;&#24049;&#20889;&#20102;&#19968;&#20010;&#27979;&#35797;&#31243;&#24207;&#65306;</span><br></pre></td></tr></table></figure>
<p>#include <sys types.h=""></sys></p>
<p>#include <sys socket.h=""></sys></p>
<p>#include <sys epoll.h=""></sys></p>
<p>#include <netdb.h></netdb.h></p>
<p>#include <string.h></string.h></p>
<p>#include <stdio.h></stdio.h></p>
<p>#include <unistd.h></unistd.h></p>
<p>#include <fcntl.h></fcntl.h></p>
<p>#include <stdlib.h></stdlib.h></p>
<p>#include <errno.h></errno.h></p>
<p>#include <sys wait.h=""></sys></p>
<p>#define PROCESS_NUM 10<br>static int<br>create_and_bind (char <em>port)<br>{<br>    int fd = socket(PF_INET, SOCK_STREAM, 0);<br>    struct sockaddr_in serveraddr;<br>    serveraddr.sin_family = AF_INET;<br>    serveraddr.sin_addr.s_addr = htonl(INADDR_ANY);<br>    serveraddr.sin_port = htons(atoi(port));<br>    bind(fd, (struct sockaddr</em>)&amp;serveraddr, sizeof(serveraddr));<br>    return fd;<br>}<br>    static int<br>make_socket_non_blocking (int sfd)<br>{<br>    int flags, s;</p>
<pre><code>flags = fcntl (sfd, F_GETFL, 0);
if (flags == -1)
{
    perror (&quot;fcntl&quot;);
    return -1;
}

flags |= O_NONBLOCK;
s = fcntl (sfd, F_SETFL, flags);
if (s == -1)
{
    perror (&quot;fcntl&quot;);
    return -1;
}

return 0;
</code></pre><p>}</p>
<p>#define MAXEVENTS 64</p>
<p>int<br>main (int argc, char <em>argv[])<br>{<br>    int sfd, s;<br>    int efd;<br>    struct epoll_event event;<br>    struct epoll_event </em>events;</p>
<pre><code>sfd = create_and_bind(&quot;1234&quot;);
if (sfd == -1)
    abort ();

s = make_socket_non_blocking (sfd);
if (s == -1)
    abort ();

s = listen(sfd, SOMAXCONN);
if (s == -1)
{
    perror (&quot;listen&quot;);
    abort ();
}

efd = epoll_create(MAXEVENTS);
if (efd == -1)
{
    perror(&quot;epoll_create&quot;);
    abort();
}

event.data.fd = sfd;
//event.events = EPOLLIN | EPOLLET;
event.events = EPOLLIN;
s = epoll_ctl(efd, EPOLL_CTL_ADD, sfd, &amp;event);
if (s == -1)
{
    perror(&quot;epoll_ctl&quot;);
    abort();
}

/* Buffer where events are returned */
events = calloc(MAXEVENTS, sizeof event);
        int k;
for(k = 0; k &lt; PROCESS_NUM; k++)
{
    int pid = fork();
    if(pid == 0)
    {

        /* The event loop */
        while (1)
        {
            int n, i;
            n = epoll_wait(efd, events, MAXEVENTS, -1);
            printf(&quot;process %d return from epoll_wait!\n&quot;, getpid());
                                   /* sleep here is very important!*/
            //sleep(2);
                                   for (i = 0; i &lt; n; i++)
            {
                if ((events[i].events &amp; EPOLLERR) || (events[i].events &amp; EPOLLHUP) || (!(events[i].events &amp;                                    EPOLLIN)))
                {
                    /* An error has occured on this fd, or the socket is not
                    ready for reading (why were we notified then?) */
                    fprintf (stderr, &quot;epoll error\n&quot;);
                    close (events[i].data.fd);
                    continue;
                }
                else if (sfd == events[i].data.fd)
                {
                    /* We have a notification on the listening socket, which
                    means one or more incoming connections. */
                    struct sockaddr in_addr;
                    socklen_t in_len;
                    int infd;
                    char hbuf[NI_MAXHOST], sbuf[NI_MAXSERV];

                    in_len = sizeof in_addr;
                    infd = accept(sfd, &amp;in_addr, &amp;in_len);
                    if (infd == -1)
                    {
                        printf(&quot;process %d accept failed!\n&quot;, getpid());
                        break;
                    }
                    printf(&quot;process %d accept successed!\n&quot;, getpid());

                    /* Make the incoming socket non-blocking and add it to the
                    list of fds to monitor. */
                    close(infd); 
                }
            }
        }
    }
}
int status;
wait(&amp;status);
free (events);
close (sfd);
return EXIT_SUCCESS;
</code></pre><p>}<br>```</p>
<p>发现确实如上面那篇博客里所说，当我模拟发起一个请求时，只有一个或少数几个进程被唤醒了。</p>
<p>也就是说，到目前为止，还没有得到一个确定的答案。但后来，在下面这篇博客中看到这样一个评论：<a href="http://blog.csdn.net/spch2008/article/details/18301357" target="_blank" rel="external">http://blog.csdn.net/spch2008/article/details/18301357</a></p>
<blockquote>
<p>这个总结，需要进一步阐述，你的实验，看上去是只有4个进程唤醒了，而事实上，其余进程没有被唤醒的原因是你的某个进程已经处理完这个 accept，内核队列上已经没有这个事件，无需唤醒其他进程。你可以在 epoll 获知这个 accept 事件的时候，不要立即去处理，而是 sleep 下，这样所有的进程都会被唤起</p>
</blockquote>
<p>看到这个评论后，我顿时如醍醐灌顶，重新修改了上面的测试程序，即在 epoll_wait 返回后，加了个 sleep 语句，这时再测试，果然发现所有的进程都被唤醒了。</p>
<p>所以，epoll_wait上的惊群确实是存在的。</p>
<h2 id="4-__u4E3A_u4EC0_u4E48_u5185_u6838_u4E0D_u5904_u7406_epoll__u60CA_u7FA4"><a href="#4-__u4E3A_u4EC0_u4E48_u5185_u6838_u4E0D_u5904_u7406_epoll__u60CA_u7FA4" class="headerlink" title="4. 为什么内核不处理 epoll 惊群"></a>4. 为什么内核不处理 epoll 惊群</h2><p>看到这里，我们可能有疑惑了，为什么内核对 accept 的惊群做了处理，而现在仍然存在 epoll 的惊群现象呢？</p>
<p>我想，应该是这样的：<br>accept 确实应该只能被一个进程调用成功，内核很清楚这一点。但 epoll 不一样，他监听的文件描述符，除了可能后续被 accept 调用外，还有可能是其他网络 IO 事件的，而其他 IO 事件是否只能由一个进程处理，是不一定的，内核不能保证这一点，这是一个由用户决定的事情，例如可能一个文件会由多个进程来读写。所以，对 epoll 的惊群，内核则不予处理。</p>
<h2 id="5-_Nginx__u662F_u5982_u4F55_u5904_u7406_u60CA_u7FA4_u95EE_u9898_u7684"><a href="#5-_Nginx__u662F_u5982_u4F55_u5904_u7406_u60CA_u7FA4_u95EE_u9898_u7684" class="headerlink" title="5. Nginx 是如何处理惊群问题的"></a>5. Nginx 是如何处理惊群问题的</h2><p>在思考这个问题之前，我们应该以前对前面所讲几点有所了解，即先弄清楚问题的背景，并能自己复现出来，而不仅仅只是看书或博客，然后再来看看 Nginx 的解决之道。这个顺序不应该颠倒。</p>
<p>首先，我们先大概梳理一下 Nginx 的网络架构，几个关键步骤为:</p>
<ol>
<li>Nginx 主进程解析配置文件，根据 listen 指令，将监听套接字初始化到全局变量 ngx_cycle 的 listening 数组之中。此时，监听套接字的创建、绑定工作早已完成。</li>
<li>Nginx 主进程 fork 出多个子进程。</li>
<li>每个子进程在 ngx_worker_process_init 方法里依次调用各个 Nginx 模块的 init_process 钩子，其中当然也包括 NGX_EVENT_MODULE 类型的 ngx_event_core_module 模块，其 init_process 钩子为 ngx_event_process_init。</li>
<li>ngx_event_process_init 函数会初始化 Nginx 内部的连接池，并把 ngx_cycle 里的监听套接字数组通过连接池来获得相应的表示连接的 ngx_connection_t 数据结构，这里关于 Nginx 的连接池先略过。我们主要看 ngx_event_process_init 函数所做的另一个工作：如果在配置文件里<strong>没有</strong>开启<a href="http://nginx.org/en/docs/ngx_core_module.html#accept_mutex" target="_blank" rel="external">accept_mutex锁</a>，就通过 ngx_add_event 将所有的监听套接字添加到 epoll 中。</li>
<li>每一个 Nginx 子进程在执行完 ngx_worker_process_init 后，会在一个死循环中执行 ngx_process_events_and_timers，这就进入到时间处理的核心逻辑了。</li>
<li>在 ngx_process_events_and_timers 中，如果在配置文件里开启了 accept_mutext 锁，子进程就会去获取 accet_mutext 锁。如果获取成功，则通过 ngx_enable_accept_events 将监听套接字添加到 epoll 中，否则，不会将监听套接字添加到 epoll 中，甚至有可能会调用 ngx_disable_accept_events 将监听套接字从 epoll 中删除（如果在之前的连接中，本worker子进程已经获得过accept_mutex锁)。</li>
<li>ngx_process_events_and_timers 继续调用 ngx_process_events，在这个函数里面阻塞调用 epoll_wait。</li>
</ol>
<p>至此，关于 Nginx 如何处理 fork 后的监听套接字，我们已经差不多理清楚了，当然还有一些细节略过了，比如在每个 Nginx 在获取 accept_mutex 锁前，还会根据当前负载来判断是否参与 accept_mutex 锁的争夺。</p>
<p>把这个过程理清了之后，Nginx 解决惊群问题的方法也就出来了，就是利用 accept_mutex 这把锁。</p>
<p>如果配置文件中没有开启 accept_mutex，则所有的监听套接字不管三七二十一，都加入到 epoll中，这样当一个新的连接来到时，所有的 worker 子进程都会惊醒。</p>
<p>如果配置文件中开启了 accept_mutex，则只有一个子进程会将监听套接字添加到 epoll 中，这样当一个新的连接来到时，当然就只有一个 worker 子进程会被唤醒了。</p>
<h2 id="6-__u5C0F_u7ED3"><a href="#6-__u5C0F_u7ED3" class="headerlink" title="6. 小结"></a>6. 小结</h2><p>现在我们对惊群及 Nginx 的处理总结如下：</p>
<ul>
<li>accept 不会有惊群，epoll_wait 才会。</li>
<li>Nginx 的 accept_mutex,并不是解决 accept 惊群问题，而是解决 epoll_wait 惊群问题。</li>
<li>说Nginx 解决了 epoll_wait 惊群问题，也是不对的，它只是控制是否将监听套接字加入到epoll 中。监听套接字只在一个子进程的 epoll 中，当新的连接来到时，其他子进程当然不会惊醒了。</li>
</ul>
<h2 id="7-__u5176_u4ED6_u53C2_u8003_u6587_u7AE0"><a href="#7-__u5176_u4ED6_u53C2_u8003_u6587_u7AE0" class="headerlink" title="7. 其他参考文章"></a>7. 其他参考文章</h2><p><a href="http://blog.csdn.net/russell_tao/article/details/7204260" target="_blank" rel="external">“惊群”，看看 nginx 是怎么解决它的</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/12/29/accept-epoll/" data-id="ciirkbb7v000058xomaymtbvw" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2015/12/27/hello-world/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Hello World</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/12/">December 2015</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2015/12/29/accept-epoll/">accept与epoll惊群</a>
          </li>
        
          <li>
            <a href="/2015/12/27/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2015 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>


<script src="/js/script.js" type="text/javascript"></script>

  </div>
</body>
</html>